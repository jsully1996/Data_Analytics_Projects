{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crime near Graffiti\n",
    "Graffiti is a common sight in Vancouver, with many of the city's buildings adorned in various artwork and murals. Since graffiti is actually illegal in Vancouver, we postulate that it may have a correlation with reduced levels of law enforcement in the vicinity and hence an increased rate of crime. We now seek to use the Graffiti Open Dataset from the catalogue to verify if there is any truth to this statement.\n",
    "<br>First we import some dependencies, start a SparkSession and read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import reverse_geocoder as rg\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from geocodio import GeocodioClient\n",
    "API_KEY = 'dd80c07f04d3066730c74d703707660d407fdcf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Spark Session and context\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"example code\")\\\n",
    "    .config(\"spark.driver.extraClassPath\",\"/home/jim/spark-2.4.0-bin-hadoop2.7/jars/mysql-connector-java-5.1.49.jar\")\\\n",
    "    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel('WARN')\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------------+\n",
      "|COUNT|LATITUDE   |LONGITUDE   |\n",
      "+-----+-----------+------------+\n",
      "|1    |49.2238602 |-123.0904255|\n",
      "|5    |49.26131589|-123.1139357|\n",
      "|4    |49.28328122|-123.1134863|\n",
      "|2    |49.2630182 |-123.1201315|\n",
      "|10   |49.26279451|-123.0923838|\n",
      "|10   |49.26279573|-123.0925276|\n",
      "|1    |49.26588693|-123.1082242|\n",
      "|1    |49.26318465|-123.1853592|\n",
      "|2    |49.29116564|-123.1322237|\n",
      "|8    |49.26497349|-123.1375141|\n",
      "+-----+-----------+------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "The Graffiti dataset has 8507 rows\n"
     ]
    }
   ],
   "source": [
    "graf_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"../Data/graffiti.csv\")\n",
    "graf_df.show(10,truncate=False)\n",
    "print('The Graffiti dataset has {} rows'.format(graf_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8054"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graf_df.select('LONGITUDE').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, we have lat/long pairs in the dataset but this is not enough to join it to any other datset based on location. The problem is that LAT/LONG pairs are never exact. For a 13 digit lat/long pair, there will exist only a single block.\n",
    "\n",
    "We on the other hand, are considering crime levels by AREA, hence we need a way to generate a 'HUNDRED_BLOCK' field from the LAT/LONG pair.\n",
    "We have a useful API that can be used to do so as to that effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------------+-----------------+\n",
      "|COUNT|LATITUDE   |LONGITUDE   |HUNDRED_BLOCK    |\n",
      "+-----+-----------+------------+-----------------+\n",
      "|1    |49.2238602 |-123.0904255|66XX FRASER ST   |\n",
      "|5    |49.26131589|-123.1139357|45XX W 12TH AVE  |\n",
      "|4    |49.28328122|-123.1134863|50XX RICHARDS ST |\n",
      "|2    |49.2630182 |-123.1201315|70XX W BROADWAY  |\n",
      "|10   |49.26279451|-123.0923838|51XX E BROADWAY  |\n",
      "|10   |49.26279573|-123.0925276|51XX E BROADWAY  |\n",
      "|1    |49.26588693|-123.1082242|16XX W 6TH AVE   |\n",
      "|1    |49.26318465|-123.1853592|36XX W 10TH AVE  |\n",
      "|2    |49.29116564|-123.1322237|16XX W GEORGIA ST|\n",
      "|8    |49.26497349|-123.1375141|14XX W 8TH AVE   |\n",
      "|5    |49.24216877|-123.0596631|22XX KINGSWAY    |\n",
      "|10   |49.2387985 |-123.0649746|50XX VICTORIA DR |\n",
      "|7    |49.26276417|-123.0886586|71XX E BROADWAY  |\n",
      "|4    |49.26386496|-123.1716457|29XX W BROADWAY  |\n",
      "|1    |49.28428105|-123.109868 |34XX WATER ST    |\n",
      "+-----+-----------+------------+-----------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latitude_list = graf_df.select(\"LATITUDE\").rdd.flatMap(lambda x: x).collect()\n",
    "longitude_list = graf_df.select(\"LONGITUDE\").rdd.flatMap(lambda x: x).collect()\n",
    "neighbourhood_list = []\n",
    "client = GeocodioClient(API_KEY)\n",
    "\n",
    "for i,j in zip(latitude_list,longitude_list):\n",
    "    location = client.reverse((i,j))\n",
    "    neighbourhood_list.append(location['results'][0]['address_components']['number'][:2]+'XX '+location['results'][0]['address_components']['formatted_street'].upper())\n",
    "\n",
    "temp_df = graf_df.toPandas()\n",
    "temp_df['HUNDRED_BLOCK'] = neighbourhood_list\n",
    "graf_df = spark.createDataFrame(temp_df)\n",
    "graf_df.show(15,truncate=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will load the dataset of crimes that is our main source of crime data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+-------------------+\n",
      "|                TYPE|     HUNDRED_BLOCK|          LATITUDE|          LONGITUDE|\n",
      "+--------------------+------------------+------------------+-------------------+\n",
      "|            Mischief|     6X E 52ND AVE| 49.22285547453633|-123.10457767461014|\n",
      "|    Theft of Vehicle|   71XX NANAIMO ST| 49.21942208176436|-123.05928356709362|\n",
      "|Break and Enter C...|   1XX E PENDER ST|49.280454355702865|-123.10100566349294|\n",
      "|            Mischief|     9XX CHILCO ST| 49.29261448054877|-123.13962081805273|\n",
      "|            Mischief|     9XX CHILCO ST| 49.29260865723727|-123.13945233120421|\n",
      "|            Mischief|24XX E HASTINGS ST|49.281126361961825| -123.0554729922974|\n",
      "|  Theft from Vehicle| 8X W BROADWAY AVE|49.263002922167225|-123.10655743565438|\n",
      "|            Mischief|24XX E HASTINGS ST| 49.28112610578195|-123.05525671257254|\n",
      "|  Theft from Vehicle|   29XX W 14TH AVE| 49.25958751890934| -123.1707943860336|\n",
      "|  Theft from Vehicle|   29XX W 14TH AVE|49.259582805051586|-123.17045353072422|\n",
      "+--------------------+------------------+------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Crime Dataset has 523093 rows\n"
     ]
    }
   ],
   "source": [
    "crime_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"..//Data/crime/crime_all_years_latlong.csv\")\n",
    "#Drop unrequired columns\n",
    "crime_df = crime_df.select(['TYPE','HUNDRED_BLOCK','LATITUDE','LONGITUDE'])\n",
    "crime_df = crime_df.dropna(how='any')\n",
    "crime_df.show(10,truncate=True)\n",
    "print(\"Crime Dataset has {} rows\".format(crime_df.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We must now get this dataset into a proper format so as it can be meaningfully joined to the Street Light data\n",
    "#### Upon merging the Hundred_BLOCK and Neighbourhood values as a common column, we can join it on the streetlight dataset (after using the same transformation on it) to sufficiently narrow down street nights in each 10-block radius and associate crime in the area with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|       HUNDRED_BLOCK|CRIME_COUNT|\n",
      "+--------------------+-----------+\n",
      "|   1XX COMMERCIAL DR|         47|\n",
      "|      6XX W 10TH AVE|        130|\n",
      "|E 48TH AVE / ELLI...|          2|\n",
      "|        36XX RAE AVE|        114|\n",
      "|   64XX CLARENDON ST|          6|\n",
      "|     28XX E 44TH AVE|         43|\n",
      "|     26XX W 20TH AVE|         10|\n",
      "|     13XX W 13TH AVE|        140|\n",
      "|          5X KERR ST|          2|\n",
      "|      1XX ONTARIO PL|         56|\n",
      "+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crime_df = crime_df.select(['TYPE','HUNDRED_BLOCK'])\n",
    "crime_df = crime_df.groupBy('HUNDRED_BLOCK').count().withColumnRenamed('count', 'CRIME_COUNT')\n",
    "crime_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+------------+-----------------+------------+\n",
      "|GRAFITI_COUNT|GRAFITI_LAT|GRAFITI_LONG|    HUNDRED_BLOCK|NO_OF_CRIMES|\n",
      "+-------------+-----------+------------+-----------------+------------+\n",
      "|            1| 49.2238602|-123.0904255|   66XX FRASER ST|          87|\n",
      "|            5|49.26131589|-123.1139357|  45XX W 12TH AVE|          39|\n",
      "|            4|49.28328122|-123.1134863| 50XX RICHARDS ST|        null|\n",
      "|            2| 49.2630182|-123.1201315|  70XX W BROADWAY|        null|\n",
      "|           10|49.26279451|-123.0923838|  51XX E BROADWAY|        null|\n",
      "|           10|49.26279573|-123.0925276|  51XX E BROADWAY|        null|\n",
      "|            1|49.26588693|-123.1082242|   16XX W 6TH AVE|          39|\n",
      "|            1|49.26318465|-123.1853592|  36XX W 10TH AVE|         149|\n",
      "|            2|49.29116564|-123.1322237|16XX W GEORGIA ST|         119|\n",
      "|            8|49.26497349|-123.1375141|   14XX W 8TH AVE|          94|\n",
      "|            5|49.24216877|-123.0596631|    22XX KINGSWAY|        null|\n",
      "|           10| 49.2387985|-123.0649746| 50XX VICTORIA DR|          94|\n",
      "|            7|49.26276417|-123.0886586|  71XX E BROADWAY|        null|\n",
      "|            4|49.26386496|-123.1716457|  29XX W BROADWAY|        null|\n",
      "|            1|49.28428105| -123.109868|    34XX WATER ST|        null|\n",
      "+-------------+-----------+------------+-----------------+------------+\n",
      "only showing top 15 rows\n",
      "\n",
      "The new Dataset has 2465 rows\n"
     ]
    }
   ],
   "source": [
    "#Create Temp tables in SPark.sql\n",
    "graf_df.createOrReplaceTempView(\"DF1\")\n",
    "crime_df.createOrReplaceTempView(\"DF2\")\n",
    "\n",
    "#SQL JOIN\n",
    "joined_df = spark.sql(\"\"\"SELECT DF1.COUNT AS GRAFITI_COUNT,DF1.LATITUDE AS GRAFITI_LAT,\n",
    "                      DF1.LONGITUDE AS GRAFITI_LONG, DF1.HUNDRED_BLOCK,\n",
    "                      DF2.CRIME_COUNT AS NO_OF_CRIMES \n",
    "                      FROM DF1 LEFT JOIN DF2 ON DF1.HUNDRED_BLOCK = DF2.HUNDRED_BLOCK\"\"\")\n",
    "joined_df.show(15,truncate=True)\n",
    "print(\"The new Dataset has {} rows\".format(joined_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.repartition(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(\"Graffiti.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the Tableau visualization:\n",
    "The locations with graffiti are plotted on the map in blue markers. The size of the marker represents the No of crimes where as their color intensity depicts count of graffiti. It can be directly observed that there is no semblance between count of graffiti and crime intensity. i.e the biggest bubbles are not the most intensely colored. The Tableau public dashboard can be found at <a href=\"https://public.tableau.com/views/Crime_vs_Graffiti/Dashboard1?:language=en&:display_count=y&publish=yes&:origin=viz_share_link\">https://public.tableau.com/views/Crime_vs_Graffiti/Dashboard1?:language=en&:display_count=y&publish=yes&:origin=viz_share_link\n",
    "</a><br>\n",
    "<img src=\"../Visualisation/Raw/Graffiti.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
