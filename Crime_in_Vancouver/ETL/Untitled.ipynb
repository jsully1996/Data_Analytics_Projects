{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crime v/s street lighting \n",
    "The stereotype of crime in a city is that most crime occurs in dark, shady alleys vs. in broad daylight. Since the Vancouver Open Data Catalogue has a neat little dataset that lists street lighting poles throughout the city, we take it upon ourselves to analyse if there is any truth in this notion that crime occurs away from lighting and in more remote places.\n",
    "<br>First we import some dependencies, start a SparkSession and read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import reverse_geocoder as rg\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Spark Session and context\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"example code\")\\\n",
    "    .config(\"spark.driver.extraClassPath\",\"/home/jim/spark-2.4.0-bin-hadoop2.7/jars/mysql-connector-java-5.1.49.jar\")\\\n",
    "    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel('WARN')\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+-----------------+------------+\n",
      "|NODE_NUMBER|LAT             |LONG             |BLOCK_NUMBER|\n",
      "+-----------+----------------+-----------------+------------+\n",
      "|1          |49.2678128146707|-123.162324988189|20          |\n",
      "|2          |49.2554200308521|-123.164303441137|26          |\n",
      "|3          |49.2555499673319|-123.164940708487|26          |\n",
      "|1          |49.2555411740844|-123.163704551483|26          |\n",
      "|3          |49.2550272963661|-123.164217031879|25          |\n",
      "|1          |49.2550311396586|-123.163320610485|25          |\n",
      "|2          |49.2550397663404|-123.163758906708|25          |\n",
      "|6          |49.2494750376237|-123.100892983293|39          |\n",
      "|2          |49.2491881601068|-123.100905232449|40          |\n",
      "|5          |49.2489134798837|-123.101144032904|40          |\n",
      "+-----------+----------------+-----------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lights_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"../Data/street_lightings/street_lighting_poles.csv\")\n",
    "#lights_df = skytrain_df.select(skytrain_df[\"LINE\"].alias(\"STATION\"), skytrain_df[\"LAT\"].alias(\"LATITUDE\"),skytrain_df[\"LONG\"].alias(\"LONGITUDE\"))\n",
    "lights_df.show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, we have lat/long pairs in the dataset but this is not enough to join it to any other datset based on location. The problem is that LAT/LONG pairs are never exact. For a 13 digit lat/long pair, there will exist only a single block.<BR> <BR> We on the other hand, are considering crime levels by AREA, hence we need a way to generate a 'Neighbourhood' field from the LAT/LONG pair.<BR> Geopy can be use to do so as to that effect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude_list = lights_df.select(\"LAT\").rdd.flatMap(lambda x: x).collect()\n",
    "longitude_list = lights_df.select(\"LONG\").rdd.flatMap(lambda x: x).collect()\n",
    "neighbourhood_list = []\n",
    "\n",
    "for i,j in zip(latitude_list,longitude_list):\n",
    "    result = rg.search([i,j])\n",
    "    neighbourhood_list.append(result[0]['name'])\n",
    "\n",
    "temp_df = lights_df.toPandas()\n",
    "temp_df['NEIGHBOURHOOD'] = neighbourhood_list\n",
    "lights_df = spark.createDataFrame(temp_df)\n",
    "lights_df.show(15,truncate=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will load the dataset of crimes that is our main source of crime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kitsilano',\n",
       " 'Arbutus-Ridge',\n",
       " 'Arbutus-Ridge',\n",
       " 'Arbutus-Ridge',\n",
       " 'Arbutus-Ridge',\n",
       " 'Arbutus-Ridge',\n",
       " 'Arbutus-Ridge',\n",
       " 'Riley Park',\n",
       " 'Riley Park',\n",
       " 'Riley Park',\n",
       " 'Riley Park',\n",
       " 'Riley Park',\n",
       " 'Riley Park',\n",
       " 'Riley Park',\n",
       " 'Grandview-Woodland',\n",
       " 'Grandview-Woodland',\n",
       " 'Grandview-Woodland',\n",
       " 'Grandview-Woodland',\n",
       " 'Grandview-Woodland',\n",
       " 'Grandview-Woodland',\n",
       " 'Kitsilano',\n",
       " 'Arbutus-Ridge',\n",
       " 'Arbutus-Ridge',\n",
       " 'Arbutus-Ridge',\n",
       " 'Arbutus-Ridge',\n",
       " 'Arbutus-Ridge',\n",
       " 'Arbutus-Ridge',\n",
       " 'Riley Park',\n",
       " 'Riley Park',\n",
       " 'Riley Park',\n",
       " 'Riley Park',\n",
       " 'Riley Park',\n",
       " 'Riley Park',\n",
       " 'Riley Park',\n",
       " 'Grandview-Woodland',\n",
       " 'Grandview-Woodland',\n",
       " 'Grandview-Woodland',\n",
       " 'Grandview-Woodland',\n",
       " 'Grandview-Woodland',\n",
       " 'Grandview-Woodland']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbourhood_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
